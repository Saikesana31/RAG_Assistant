# RAG Agent - Intelligent Document Q&A System

A production-ready Retrieval-Augmented Generation (RAG) system built with FastAPI, Inngest, and Qdrant. This project enables semantic search and question-answering over your PDF documents using state-of-the-art embeddings and LLMs.

[![Python](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.128+-green.svg)](https://fastapi.tiangolo.com/)
[![Inngest](https://img.shields.io/badge/Inngest-0.5.13-purple.svg)](https://www.inngest.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

## ğŸ“‹ Table of Contents

- [Introduction](#introduction)
- [Tech Stack](#tech-stack)
- [Architecture](#architecture)
- [Features](#features)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Environment Setup](#environment-setup)
- [Usage](#usage)
  - [Running the Application](#running-the-application)
  - [Ingesting Documents](#ingesting-documents)
  - [Querying Documents](#querying-documents)
- [Project Structure](#project-structure)
- [Deployment](#deployment)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Introduction

This RAG Agent transforms static PDF documents into an intelligent, queryable knowledge base. Users can:

- **Upload PDF documents** for automatic processing and indexing
- **Ask natural language questions** and receive contextual answers
- **Track processing status** in real-time via Inngest workflows
- **Access source attribution** for every answer generated

Perfect for building internal knowledge bases, customer support systems, research assistants, or any application requiring document understanding.

---

## ğŸ› ï¸ Tech Stack

### Core Framework
- **[FastAPI](https://fastapi.tiangolo.com/)** `0.128+` - Modern, high-performance web framework
- **[Uvicorn](https://www.uvicorn.org/)** `0.40+` - ASGI server for production deployment

### Workflow Orchestration
- **[Inngest](https://www.inngest.com/)** `0.5.13+` - Event-driven workflow engine with built-in retry logic and observability

### Vector Database
- **[Qdrant](https://qdrant.tech/)** - High-performance vector similarity search engine
  - Cosine similarity for semantic matching
  - 3072-dimensional vector space
  - Persistent storage

### AI/ML Stack
- **[OpenAI API](https://openai.com/)**
  - `text-embedding-3-large` - 3072-dimensional embeddings
  - `gpt-4o-mini` - Efficient LLM for answer generation
- **[llama-index](https://www.llamaindex.ai/)** - Document processing and chunking
  - `PDFReader` for PDF extraction
  - `SentenceSplitter` for intelligent chunking

### Frontend
- **[Streamlit](https://streamlit.io/)** - Interactive web UI for rapid prototyping

### Type Safety & Validation
- **[Pydantic](https://pydantic.dev/)** `2.12+` - Data validation and settings management

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      User Interface Layer                    â”‚
â”‚                    (Streamlit Frontend)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP Requests
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API Layer (FastAPI)                        â”‚
â”‚  â€¢ /events endpoint (receives Inngest events)               â”‚
â”‚  â€¢ /health endpoint (health checks)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Event Triggers
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Workflow Orchestration (Inngest)                â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ rag/ingest_pdf     â”‚      â”‚  rag/query_pdf      â”‚       â”‚
â”‚  â”‚                    â”‚      â”‚                     â”‚       â”‚
â”‚  â”‚ 1. Load PDF        â”‚      â”‚  1. Embed query     â”‚       â”‚
â”‚  â”‚ 2. Chunk text      â”‚      â”‚  2. Search vectors  â”‚       â”‚
â”‚  â”‚ 3. Generate        â”‚      â”‚  3. Retrieve contextâ”‚       â”‚
â”‚  â”‚    embeddings      â”‚      â”‚  4. Generate answer â”‚       â”‚
â”‚  â”‚ 4. Upsert to       â”‚      â”‚                     â”‚       â”‚
â”‚  â”‚    Qdrant          â”‚      â”‚                     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚           â”‚                             â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                             â”‚
            â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Processing Layer                     â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  data_loader.py â”‚         â”‚   OpenAI API     â”‚          â”‚
â”‚  â”‚                 â”‚         â”‚                  â”‚          â”‚
â”‚  â”‚ â€¢ PDFReader     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ â€¢ Embeddings     â”‚          â”‚
â”‚  â”‚ â€¢ Sentence      â”‚         â”‚ â€¢ Chat           â”‚          â”‚
â”‚  â”‚   Splitter      â”‚         â”‚   Completions    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Vector Storage Layer (Qdrant)                â”‚
â”‚                                                              â”‚
â”‚  â€¢ Collection: rag_collection                                â”‚
â”‚  â€¢ Vectors: 3072 dimensions (text-embedding-3-large)        â”‚
â”‚  â€¢ Distance: Cosine similarity                               â”‚
â”‚  â€¢ Payloads: {source, text}                                  â”‚
â”‚  â€¢ Persistence: Local or cloud-hosted                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

#### Ingestion Pipeline
```
PDF Upload â†’ Streamlit UI â†’ Inngest Event (rag/ingest_pdf)
    â†“
Load PDF (PDFReader) â†’ Extract Text
    â†“
Chunk Text (SentenceSplitter: 1000 chars, 200 overlap)
    â†“
Generate Embeddings (OpenAI text-embedding-3-large, 3072-dim)
    â†“
Upsert to Qdrant (Collection: rag_collection)
    â†“
Return Ingestion Status
```

#### Query Pipeline
```
User Question â†’ Streamlit UI â†’ Inngest Event (rag/query_pdf)
    â†“
Embed Question (OpenAI text-embedding-3-large)
    â†“
Vector Search (Qdrant, top_k=5, cosine similarity)
    â†“
Retrieve Context Chunks + Sources
    â†“
Build Prompt (Context + Question)
    â†“
Generate Answer (OpenAI gpt-4o-mini)
    â†“
Return {answer, sources, num_contexts}
```

### Key Components

#### 1. **custom_types.py** - Type Definitions
- `RAGChunkAndSrc`: Chunked document data
- `RAGUpsertResult`: Ingestion confirmation
- `RAGSearchResult`: Retrieved context and sources
- `RAGQueryResult`: Final answer with metadata

#### 2. **data_loader.py** - Document Processing
- PDF loading with llama-index PDFReader
- Semantic chunking with SentenceSplitter
- Embedding generation via OpenAI API

#### 3. **vector_DB.py** - Qdrant Interface
- Collection management
- Vector upsert with payloads
- Similarity search with metadata retrieval

#### 4. **main.py** - FastAPI + Inngest Integration
- Two Inngest functions: `rag_ingest_pdf`, `rag_query_pdf`
- Event-driven step execution
- Type-safe serialization with Pydantic

#### 5. **streamlit.py** - User Interface
- PDF upload interface
- Question/answer form
- Real-time status polling

---

## âœ¨ Features

### Core Capabilities
- âœ… **Semantic Search** - Find relevant information across documents
- âœ… **Context-Aware Answers** - AI-generated responses based on your data
- âœ… **Source Attribution** - Know which documents contributed to each answer
- âœ… **Async Processing** - Non-blocking workflows with Inngest
- âœ… **Real-Time Status** - Poll workflow status via Inngest API

### Technical Highlights
- âœ… **Event-Driven Architecture** - Scalable, resilient workflows
- âœ… **Type Safety** - Pydantic models throughout
- âœ… **Chunk Overlap** - Better context preservation (200 char overlap)
- âœ… **Deterministic IDs** - UUID5 based on source + index
- âœ… **Configurable Top-K** - Adjust retrieval count per query

---

## ğŸš€ Getting Started

### Prerequisites

Before you begin, ensure you have the following installed:

- **Python 3.12+** - [Download](https://www.python.org/downloads/)
- **Docker** (for Qdrant) - [Download](https://www.docker.com/get-started)
- **OpenAI API Key** - [Get yours](https://platform.openai.com/api-keys)
- **Inngest Dev Server** - [Install](https://www.inngest.com/docs/local-development)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/rag-agent.git
   cd rag-agent
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   # Using pip
   pip install -r requirements.txt

   # Or using uv (faster)
   uv pip install -r requirements.txt
   ```

### Environment Setup

1. **Create a `.env` file** in the project root:
   ```env
   # OpenAI Configuration
   OPENAI_API_KEY=sk-your-openai-api-key-here

   # Inngest Configuration
   INNGEST_API_BASE=http://127.0.0.1:8288  # Local dev server
   INNGEST_SIGNING_KEY=your-signing-key    # Optional for local dev
   INNGEST_EVENT_KEY=your-event-key        # Optional for local dev

   # Qdrant Configuration (optional, defaults to localhost)
   QDRANT_URL=http://localhost:6333
   QDRANT_COLLECTION=rag_collection
   ```

2. **Start Qdrant** (using Docker)
   ```bash
   docker run -p 6333:6333 -p 6334:6334 \
       -v $(pwd)/qdrant_storage:/qdrant/storage \
       qdrant/qdrant
   ```

   Or use Qdrant Cloud:
   ```bash
   # Update .env with your cloud URL
   QDRANT_URL=https://your-cluster.qdrant.io
   QDRANT_API_KEY=your-api-key
   ```

3. **Install and start Inngest Dev Server**
   ```bash
   # Install Inngest CLI
   npm install -g inngest-cli

   # Start dev server
   inngest dev
   ```

---

## ğŸ“– Usage

### Running the Application

1. **Start the FastAPI server**
   ```bash
   uvicorn main:app --reload --port 8000
   ```

2. **In a new terminal, start Streamlit**
   ```bash
   streamlit run streamlit.py
   ```

3. **Access the application**
   - Streamlit UI: http://localhost:8501
   - FastAPI Docs: http://localhost:8000/docs
   - Inngest Dev UI: http://localhost:8288

### Ingesting Documents

1. Navigate to the Streamlit UI
2. Click **"Choose a PDF"** and select your document
3. The system will:
   - Upload the file to `uploads/` directory
   - Trigger the `rag/ingest_pdf` event
   - Process chunks in the background
   - Display success message when complete

**Behind the scenes:**
```python
# Event triggered
{
  "name": "rag/ingest_pdf",
  "data": {
    "pdf_path": "/path/to/document.pdf",
    "source_id": "document.pdf"
  }
}

# Workflow steps
Step 1: load_chunks â†’ Extract and chunk text
Step 2: embeddings_upsert â†’ Embed and store in Qdrant
```

### Querying Documents

1. Enter your question in the text input
2. Adjust **"How many chunks to retrieve"** (default: 5)
3. Click **"Ask"**
4. View the answer and source documents

**Behind the scenes:**
```python
# Event triggered
{
  "name": "rag/query_pdf",
  "data": {
    "question": "What is the main topic?",
    "top_k": 5
  }
}

# Workflow steps
Step 1: embed_search â†’ Vector similarity search
Step 2: call-openai â†’ Generate contextual answer

# Response
{
  "answer": "The main topic is...",
  "sources": ["doc1.pdf", "doc2.pdf"],
  "num_contexts": 5
}
```

---

## ğŸ“ Project Structure

```
rag-agent/
â”‚
â”œâ”€â”€ main.py                  # FastAPI app + Inngest functions
â”œâ”€â”€ data_loader.py           # PDF processing and embedding
â”œâ”€â”€ vector_DB.py             # Qdrant client wrapper
â”œâ”€â”€ custom_types.py          # Pydantic models
â”œâ”€â”€ streamlit.py             # Streamlit UI
â”‚
â”œâ”€â”€ uploads/                 # Uploaded PDF storage
â”œâ”€â”€ qdrant_storage/          # Qdrant persistent storage (if local)
â”‚
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ pyproject.toml          # Project metadata (uv/poetry)
â”œâ”€â”€ uv.lock                 # Locked dependencies
â”‚
â”œâ”€â”€ .env                    # Environment variables (create this)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md               # This file
```

---

## ğŸš¢ Deployment

### Docker Deployment

**Assumptions:**
- Production Qdrant instance (cloud or self-hosted)
- Inngest Cloud account for production workflows
- Environment variables configured

1. **Create `Dockerfile`**
   ```dockerfile
   FROM python:3.12-slim

   WORKDIR /app

   COPY requirements.txt .
   RUN pip install --no-cache-dir -r requirements.txt

   COPY . .

   EXPOSE 8000

   CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
   ```

2. **Build and run**
   ```bash
   docker build -t rag-agent .
   docker run -p 8000:8000 --env-file .env rag-agent
   ```

### Cloud Deployment Options

#### Option 1: Railway / Render
- Push to GitHub
- Connect repository to platform
- Set environment variables
- Deploy FastAPI app
- Deploy Streamlit separately (or combine)

#### Option 2: AWS / GCP / Azure
- **Compute:** ECS, Cloud Run, or App Service
- **Vector DB:** Qdrant Cloud or self-hosted on EC2/Compute Engine
- **Inngest:** Inngest Cloud (recommended for production)

#### Option 3: Kubernetes
- Deploy FastAPI as a Deployment
- Use Qdrant Helm chart or managed service
- Configure Inngest Cloud webhook

### Production Checklist

- [ ] Set up Qdrant Cloud or production instance
- [ ] Configure Inngest Cloud account
- [ ] Store secrets in vault (AWS Secrets Manager, etc.)
- [ ] Enable CORS if needed for Streamlit
- [ ] Set up logging and monitoring
- [ ] Configure rate limiting for OpenAI API
- [ ] Add authentication to FastAPI endpoints
- [ ] Set up CI/CD pipeline
- [ ] Configure backup for Qdrant data

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Make your changes**
   - Follow PEP 8 style guidelines
   - Add type hints
   - Update tests if applicable
4. **Commit your changes**
   ```bash
   git commit -m "Add amazing feature"
   ```
5. **Push to your branch**
   ```bash
   git push origin feature/amazing-feature
   ```
6. **Open a Pull Request**

### Development Guidelines

- Use Pydantic models for all data structures
- Add type hints to all functions
- Write docstrings for public methods
- Test with multiple PDF formats
- Update README for new features

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/) for the excellent web framework
- [Inngest](https://www.inngest.com/) for workflow orchestration
- [Qdrant](https://qdrant.tech/) for vector search capabilities
- [OpenAI](https://openai.com/) for embeddings and LLM
- [llama-index](https://www.llamaindex.ai/) for document processing

---

## ğŸ“¬ Contact

**Questions or suggestions?**
- Open an issue on GitHub
- Connect on LinkedIn:www.linkedin.com/in/saikesana
- Email: kesana.class2024@gmail.com

---

**Built with â¤ï¸ using Python and modern AI/ML tools**
